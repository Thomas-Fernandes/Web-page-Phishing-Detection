trControl = ctrl, preProcess = c("center","scale"))
set.seed(123)
indxTest <- createDataPartition(df$status, p = 0.15, list = FALSE)
DTest <- df[indxTest, ]
Dsub <- df[-indxTest, ]
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- Dsub[indxTrain, ]
Dval <- Dsub[-indxTrain, ]
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(DTrain), "\n"
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(Dsub), "\n")
set.seed(123)
indxTest <- createDataPartition(df$status, p = 0.15, list = FALSE)
DTest <- df[indxTest, ]
Dsub <- df[-indxTest, ]
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- Dsub[indxTrain, ]
Dval <- Dsub[-indxTrain, ]
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(DTrain), "\n")
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(Dsub), "\n")
cat("Nombre d'observations dans l'ensemble de test:", nrow(DTest), "\n")
cat("Nombre d'observations dans l'ensemble de validation:", nrow(Dval), "\n")
set.seed(123)
indxTest <- createDataPartition(df$status, p = 0.15, list = FALSE)
DTest <- df[indxTest, ]
Dsub <- df[-indxTest, ]
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- Dsub[indxTrain, ]
Dval <- Dsub[-indxTrain, ]
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(DTrain), "\n")
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(Dsub), "\n")
cat("Nombre d'observations dans l'ensemble de validation:", nrow(Dval), "\n")
cat("Nombre d'observations dans l'ensemble de test:", nrow(DTest), "\n")
set.seed(123)
indxTest <- createDataPartition(df$status, p = 0.15, list = FALSE)
DTest <- df[indxTest, ]
Dsub <- df[-indxTest, ]
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- Dsub[indxTrain, ]
Dval <- Dsub[-indxTrain, ]
cat("Nombre d'observations dans l'ensemble de test:", nrow(DTest), "\n")
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(Dsub), "\n")
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(DTrain), "\n")
cat("Nombre d'observations dans l'ensemble de validation:", nrow(Dval), "\n")
set.seed(123)
indxTest <- createDataPartition(df$status, p = 0.15, list = FALSE)
DTest <- df[indxTest, ]
Dsub <- df[-indxTest, ]
indxTrain <- createDataPartition(Dsub$status, p = 0.75, list = FALSE)
DTrain <- Dsub[indxTrain, ]
Dval <- Dsub[-indxTrain, ]
cat("Nombre d'observations dans l'ensemble de test:", nrow(DTest), "\n")
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(Dsub), "\n")
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(DTrain), "\n")
cat("Nombre d'observations dans l'ensemble de validation:", nrow(Dval), "\n")
2428+7286
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = Dsub,
method = "knn",
trControl = ctrl,
tuneGrid = data.frame(k = 5),
preProcess = c("center", "scale"),
na.action = na.omit)
fit.lr = train(status ~ ., data = Dsub, method = "glm",
trControl = ctrl, preProcess = c("center","scale"))
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = Dsub,
method = "knn",
trControl = ctrl,
tuneGrid = data.frame(k = 5),
preProcess = c("center", "scale"),
na.action = na.omit)
fit.lr = train(status ~ ., data = Dsub, method = "glm",
trControl = ctrl, preProcess = c("center","scale"))
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = Dsub,
method = "knn",
trControl = ctrl,
tuneGrid = data.frame(k = 5),
preProcess = c("center", "scale"),
na.action = na.omit)
fit.lr = train(status ~ .,
data = Dsub,
method = "glm",
trControl = ctrl,
preProcess = c("center","scale"),
na.action = na.omit)
score.knn = predict(fit.knn ,newdata= Dtest,type="prob")
score.lr = predict(fit.lr ,newdata= Dtest,type="prob")
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = Dsub,
method = "knn",
trControl = ctrl,
tuneGrid = data.frame(k = 5),
preProcess = c("center", "scale"),
na.action = na.omit)
fit.lr = train(status ~ .,
data = Dsub,
method = "glm",
trControl = ctrl,
preProcess = c("center","scale"),
na.action = na.omit)
score.knn = predict(fit.knn ,newdata= Dtest,type="prob")
score.lr = predict(fit.lr ,newdata= Dtest,type="prob")
score.data = cbind(Dtest$status,score.knn["phishing"],score.lr["phishing"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data,"type.test",c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
print(calc_auc(g)$AUC)
score.lr$phishing
library(caret)
# Obtenir les prédictions
predictions.knn <- predict(fit.knn, newdata = Dtest)
predictions.lr <- predict(fit.lr, newdata = Dtest)
# Créer la matrice de confusion
confusionMatrix(predictions.knn, Dtest$status)
confusionMatrix(predictions.lr, Dtest$status)
score.data = cbind(Dtest$status,score.knn["phishing"],score.lr["phishing"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data,"type.test",c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
print(calc_auc(g)$AUC)
score.knn = predict(fit.knn ,newdata = Dval, type="prob")
score.lr = predict(fit.lr ,newdata = Dval, type="prob")
score.knn
score.data = cbind(Dtest$status,score.knn["phishing"],score.lr["phishing"])
score.data = cbind(Dval$status,score.knn["phishing"],score.lr["phishing"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data,"type.test",c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
print(calc_auc(g)$AUC)
score.data = cbind(Dtest$status,score.knn["phishing"],score.lr["phishing"])
score.data = cbind(DTest$status,score.knn["phishing"],score.lr["phishing"])
gc()
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(caret)
library(tidyr)
df <- read_csv("dataset_phishing.csv", show_col_types = FALSE)
df <- df[,-1]
df$status <- as.factor(df$status)
df_present <- df
#Extraire les variables qualitatives
v_quali <- vector("logical", length = ncol(df_present) - 1)
for (i in 2:ncol(df_present)) {
v_quali[[i]] <- (length(unique(df_present[[i]])) / sum(!is.na(df_present[[i]]))) < 0.002
}
num_cols <- character()
cat_cols <- character()
for (i in 1:length(v_quali)) {
if (!v_quali[[i]]) {
num_cols <- c(num_cols, names(df_present)[i])
} else {
cat_cols <- c(cat_cols, names(df_present)[i])
}
}
corr <- cor(df_present[num_cols])
ggcorrplot(
corr,
hc.order = TRUE,
type = "full",
outline.color = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"),
show.diag = TRUE,
tl.cex = 7,
tl.srt = 90
)
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(.data[[col_name]], na.rm = TRUE))
}
# Liste pour stocker les résultats des variables qualitatives
mean_values_list_cat <- list()
# Calculer la moyenne pour chaque colonne qualitative
for (col in cat_cols) {
mean_values_list_cat[[col]] <- mean_by_status(df_present, col)
}
# Convertir les résultats en un dataframe utilisable pour ggplot
mean_values_df_cat <- do.call(rbind, mean_values_list_cat)
mean_values_df_cat$col_names <- rownames(mean_values_df_cat)
#On ne garder que les variables qui ont une différence de moyenne significative entre les deux statuts
mean_values_df_cat <- mean_values_df_cat[mean_values_df_cat$mean_value > 0.1 | mean_values_df_cat$mean_value < -0.1,]
mean_values_df_cat <- mean_values_df_cat[!is.na(mean_values_df_cat$mean_value), ]
# Tracer le graphique à barres pour les variables qualitatives
ggplot(mean_values_df_cat, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables qualitatives par statut") +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
# Liste pour stocker les résultats des variables quantitatives
mean_values_list_num <- list()
# Calculer la moyenne pour chaque colonne quantitative
for (col in num_cols) {
if (col != "web_traffic" && col != "domain_age" && col != "domain_registration_length") {
mean_values_list_num[[col]] <- mean_by_status(df_present, col)
}
}
# Convertir les résultats en un dataframe utilisable pour ggplot
mean_values_df_num <- do.call(rbind, mean_values_list_num)
mean_values_df_num$col_names <- rownames(mean_values_df_num)
# On ne garde que les variables qui ont une différence de moyenne significative entre les deux statuts
mean_values_df_num <- mean_values_df_num[mean_values_df_num$mean_value > 0.3 | mean_values_df_num$mean_value < -0.3,]
mean_values_df_num <- mean_values_df_num[!is.na(mean_values_df_num$mean_value), ]
# Tracer le graphique à barres pour les variables quantitatives
ggplot(mean_values_df_num, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables quantitatives par statut") +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
set.seed(123)
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- df[indxTrain, ]
DTest <- df[-indxTrain, ]
cat("Nombre d'observations dans l'ensemble d'entraînement:", nrow(DTrain), "\n")
cat("Nombre d'observations dans l'ensemble de test:", nrow(DTest), "\n")
set.seed(123)
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = DTrain,
method = "knn",
tuneGrid = data.frame(k = 5),
trControl = ctrl,
na.action = na.omit)
predictions <- predict(fit.knn, newdata = DTest)
confusionMatrix <- confusionMatrix(predictions, DTest$status)
print(confusionMatrix$table)
print(confusionMatrix$overall['Accuracy'])
errorRate <- 1 - confusionMatrix$overall['Accuracy']
print(errorRate)
set.seed(123)
ctrl <- trainControl(method = "cv", number = 10)
fit.knn.cv <- train(status ~ .,
data = DTrain,
method = "knn",
trControl = ctrl,
tuneLength = 20,
preProcess = c("center", "scale"),
na.action = na.omit)
plot(fit.knn.cv)
print(fit.knn.cv$results)
print(fit.knn.cv$bestTune)
bestK <- fit.knn.cv$bestTune$k
predictionsBestK <- predict(fit.knn.cv, newdata = DTest)
confusionMatrixBestK <- confusionMatrix(predictionsBestK, DTest$status)
errorRateBestK <- 1 - confusionMatrixBestK$overall['Accuracy']
print(errorRateBestK)
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = DTrain,
method = "knn",
trControl = ctrl,
tuneGrid = data.frame(k = 5),
preProcess = c("center", "scale"),
na.action = na.omit)
fit.lr = train(status ~ .,
data = DTrain,
method = "glm",
trControl = ctrl,
preProcess = c("center","scale"),
na.action = na.omit)
score.knn = predict(fit.knn ,newdata = DTest, type="prob")
score.lr = predict(fit.lr ,newdata = DTest, type="prob")
score.data = cbind(DTest$status,score.knn["phishing"],score.lr["phishing"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data,"type.test",c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
print(calc_auc(g)$AUC)
ctrl <- trainControl(method = "none")
fit.knn <- train(status ~ .,
data = DTrain,
method = "knn",
trControl = ctrl,
tuneGrid = data.frame(k = 5),
na.action = na.omit)
fit.lr = train(status ~ .,
data = DTrain,
method = "glm",
trControl = ctrl,
na.action = na.omit)
score.knn = predict(fit.knn ,newdata = DTest, type="prob")
score.lr = predict(fit.lr ,newdata = DTest, type="prob")
score.data = cbind(DTest$status,score.knn["phishing"],score.lr["phishing"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data,"type.test",c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
print(calc_auc(g)$AUC)
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(.data[[col_name]], na.rm = TRUE))
}
mean_values_list_cat <- list()
for (col in cat_cols) {
mean_values_list_cat[[col]] <- mean_by_status(df_present, col)
}
mean_values_df_cat <- do.call(rbind, mean_values_list_cat)
mean_values_df_cat$col_names <- rownames(mean_values_df_cat)
mean_values_df_cat <- mean_values_df_cat[mean_values_df_cat$mean_value > 0.1 | mean_values_df_cat$mean_value < -0.1,]
mean_values_df_cat <- mean_values_df_cat[!is.na(mean_values_df_cat$mean_value), ]
ggplot(mean_values_df_cat, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables qualitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
mean_values_list_num <- list()
for (col in num_cols) {
if (col != "web_traffic" && col != "domain_age" && col != "domain_registration_length") {
mean_values_list_num[[col]] <- mean_by_status(df_present, col)
}
}
mean_values_df_num <- do.call(rbind, mean_values_list_num)
mean_values_df_num$col_names <- rownames(mean_values_df_num)
mean_values_df_num <- mean_values_df_num[mean_values_df_num$mean_value > 0.3 | mean_values_df_num$mean_value < -0.3,]
mean_values_df_num <- mean_values_df_num[!is.na(mean_values_df_num$mean_value), ]
ggplot(mean_values_df_num, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables quantitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
# Calculer les moyennes des caractéristiques numériques par rapport à la variable cible
mean_df <- df_present %>%
group_by(status) %>%
summarise(across(where(is.numeric), mean, na.rm = TRUE))
# Mettre les données sous forme de long format pour la visualisation
mean_df_long <- mean_df %>%
pivot_longer(cols = -status, names_to = "Numerical_Features", values_to = "Mean_Values")
# Créer le graphique de distribution
ggplot(mean_df_long, aes(x = Numerical_Features, y = Mean_Values, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Distribution of Mean values of the Numerical features across Target variable",
x = "Numerical Features", y = "Mean Values") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotation des étiquettes sur l'axe x pour une meilleure lisibilité
# Calculer la moyenne des variables numériques en fonction de la variable cible
df_distr <- df %>%
group_by(status) %>%
summarize(across(all_of(num_cols), mean)) %>%
t() %>%
as.data.frame()
# Renommer les colonnes
colnames(df_distr) <- c("0_Label", "1_Label")
# Tracer le graphique
barplot(as.matrix(df_distr[2:(length(df_distr) - 3),]),
main = "Distribution of Average values across Target",
xlab = "Numerical Features",
ylab = "Average Values",
col = c("skyblue", "salmon"),
beside = TRUE,
legend.text = TRUE,
args.legend = list(x = "topright", bty = "n"),
ylim = c(0, 500000))
# Calculer la moyenne des variables numériques en fonction de la variable cible
df_distr <- df %>%
group_by(status) %>%
summarize(across(all_of(num_cols), mean)) %>%
t() %>%
as.data.frame()
# Renommer les colonnes
colnames(df_distr) <- c("0_Label", "1_Label")
# Tracer le graphique
# Supposons que df_distr est correctement créé
# Assurez-vous que df_distr est correctement organisé et ne contient que les valeurs numériques pour le tracé.
# Exemple de code pour tracer le graphique à barres
barplot(as.matrix(df_distr[-c(1, length(df_distr)), ]),
main = "Distribution of Average values across Target",
xlab = "Numerical Features",
ylab = "Average Values",
col = c("skyblue", "salmon"),
beside = TRUE,
ylim = c(0, 500000))
ggplot(data = melt(df_present[, num_cols]), aes(x = variable, y = value)) +
geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(caret)
library(tidyr)
library(reshape2)
df <- read_csv("dataset_phishing.csv", show_col_types = FALSE)
df <- df[,-1]
df$status <- as.factor(df$status)
df_present <- df
#Extraire les variables qualitatives
v_quali <- vector("logical", length = ncol(df_present) - 1)
for (i in 2:ncol(df_present)) {
v_quali[[i]] <- (length(unique(df_present[[i]])) / sum(!is.na(df_present[[i]]))) < 0.002
}
num_cols <- character()
cat_cols <- character()
for (i in 1:length(v_quali)) {
if (!v_quali[[i]]) {
num_cols <- c(num_cols, names(df_present)[i])
} else {
cat_cols <- c(cat_cols, names(df_present)[i])
}
}
corr <- cor(df_present[num_cols])
ggcorrplot(
corr,
hc.order = TRUE,
type = "full",
outline.color = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"),
show.diag = TRUE,
tl.cex = 7,
tl.srt = 90
)
ggplot(data = melt(df_present[, num_cols]), aes(x = variable, y = value)) +
geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
class.lr.aic <- predict(fit.lr.aic, newdata = DTest)
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.lr.aic.RDATA")
class.lr.aic <- predict(fit.lr.aic, newdata = DTest)
(confusionMatrix(class.lr.aic, DTest$status))
gc()
attach(phishing)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(caret)
library(tidyr)
library(reshape2)
library(plotROC)
library(ROCR)
df <- read_csv("dataset_phishing.csv", show_col_types = FALSE)
df <- df[,-1]
df$status <- as.factor(df$status)
df_present <- df
#Extraire les variables qualitatives
v_quali <- vector("logical", length = ncol(df_present) - 1)
for (i in 2:ncol(df_present)) {
v_quali[[i]] <- (length(unique(df_present[[i]])) / sum(!is.na(df_present[[i]]))) < 0.002
}
num_cols <- character()
cat_cols <- character()
for (i in 1:length(v_quali)) {
if (!v_quali[[i]]) {
num_cols <- c(num_cols, names(df_present)[i])
} else {
cat_cols <- c(cat_cols, names(df_present)[i])
}
}
corr <- cor(df_present[num_cols])
ggcorrplot(
corr,
hc.order = TRUE,
type = "full",
outline.color = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"),
show.diag = TRUE,
tl.cex = 7,
tl.srt = 90
)
ggplot(data = melt(df_present[, num_cols]), aes(x = variable, y = value)) +
geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
attach(df)
ggplot(df, aes(x = log(length_url), y = log(domain_age))) +
geom_point() +
labs(x = "Longueur de l'URL", y = "Âge du domaine") +
ggtitle("Nuage de points : Longueur de l'URL vs Âge du domaine")
max(domain_age)
min(domain_age)
# Nuage de point y = longueur url, x = status
ggplot(df, aes(x = status, y = length_url)) +
geom_point() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Nuage de points : Longueur de l'URL vs Status")
# Boxplot
ggplot(df, aes(x = status, y = log(length_url))) +
geom_boxplot() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Boxplot : Longueur de l'URL vs Status")
attach(df)
ggplot(df, aes(x = log(length_url), y = log(domain_age))) +
geom_point() +
labs(x = "Longueur de l'URL", y = "Âge du domaine") +
ggtitle("Nuage de points : Longueur de l'URL vs Âge du domaine")
max(domain_age)
min(domain_age)
# Nuage de point y = longueur url, x = status
ggplot(df, aes(x = status, y = length_url)) +
geom_point() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Nuage de points : Longueur de l'URL vs Status")
# Boxplot
ggplot(df, aes(x = status, y = log(length_url))) +
geom_boxplot() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Boxplot : Longueur de l'URL vs Status")
