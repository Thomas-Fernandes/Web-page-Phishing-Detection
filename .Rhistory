} else {
cat_cols <- c(cat_cols, names(df_present)[i])
}
}
corr <- cor(df_present[num_cols])
ggcorrplot(
corr,
hc.order = TRUE,
type = "full",
outline.color = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"),
show.diag = TRUE,
tl.cex = 7,
tl.srt = 90
)
ggplot(data = melt(df_present[, num_cols]), aes(x = variable, y = value)) +
geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
attach(df)
ggplot(df, aes(x = nb_underscore, y = nb_hyphens )) +
geom_point() +
labs(x = "Nombre tiret du bas", y = "Nombre de tirets") +
ggtitle("Nuage de points : Nombre tiret du bas vs Nombre de tirets")
ggplot(df, aes(x = domain_age, y = ratio_extHyperlinks)) +
geom_point() +
labs(x = "Âge du domaine", y = "Nombre de liens externes") +
ggtitle("Nuage de points : Âge du domaines vs Nombre de liens externes")
max(domain_age)
min(domain_age)
# Nuage de point y = longueur url, x = status
ggplot(df, aes(x = status, y = length_url)) +
geom_point() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Nuage de points : Longueur de l'URL vs Status")
# Boxplot
ggplot(df, aes(x = status, y = log(length_url))) +
geom_boxplot() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Boxplot : Longueur de l'URL vs Status")
# Créer un dataframe pour les variables qualitatives binaires (valeurs 0 ou 1 uniquement)
quali <- df[, sapply(df, function(col) all(col %in% c(0, 1)))]
# Ajouter la colonne status au dataframe quali
quali$status <- df$status
# Créer un dataframe pour les variables quantitatives (valeurs autres que 0 et 1)
quanti <- df[, sapply(df, function(col) !all(col %in% c(0, 1)))]
# Ajouter la colonne status au dataframe quanti
quanti$status <- df$status
# Fonction pour calculer la moyenne par status
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(.data[[col_name]], na.rm = TRUE))
}
# Calcul des moyennes pour les variables qualitatives binaires
mean_values_list_quali <- lapply(names(quali)[names(quali) != "status"], function(col) {
mean_by_status(quali, col)
})
mean_values_df_quali <- do.call(rbind, mean_values_list_quali)
rownames(mean_values_df_quali) <- NULL
# Calcul des moyennes pour les variables quantitatives
mean_values_list_quanti <- lapply(names(quanti)[names(quanti) != "status"], function(col) {
mean_by_status(quanti, col)
})
mean_values_df_quanti <- do.call(rbind, mean_values_list_quanti)
rownames(mean_values_df_quanti) <- NULL
# Créer les graphiques
ggplot(mean_values_df_quali, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables qualitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
# Créer un dataframe pour les variables qualitatives binaires (valeurs 0 ou 1 uniquement)
quali <- df[, sapply(df, function(col) all(col %in% c(0, 1)))]
# Ajouter la colonne status au dataframe quali
quali$status <- df$status
# Créer un dataframe pour les variables quantitatives (valeurs autres que 0 et 1)
quanti <- df[, sapply(df, function(col) !all(col %in% c(0, 1)))]
# Ajouter la colonne status au dataframe quanti
quanti$status <- df$status
# Fonction pour calculer la moyenne par status
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(.data[[col_name]], na.rm = TRUE))
}
# Calcul des moyennes pour les variables qualitatives binaires
mean_values_list_quali <- lapply(names(quali)[names(quali) != "status"], function(col) {
mean_by_status(quali, col)
})
mean_values_df_quali <- do.call(rbind, mean_values_list_quali)
rownames(mean_values_df_quali) <- NULL
# Calcul des moyennes pour les variables quantitatives
mean_values_list_quanti <- lapply(names(quanti)[names(quanti) != "status"], function(col) {
mean_by_status(quanti, col)
})
mean_values_df_quanti <- do.call(rbind, mean_values_list_quanti)
rownames(mean_values_df_quanti) <- NULL
# Créer les graphiques
ggplot(mean_values_df_quali, aes(x = col_name, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables qualitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
attach(quali)
View(quanti)
View(quali)
# Fonction pour calculer la moyenne par statut
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(get(col_name), na.rm = TRUE), .groups = 'drop') %>%
mutate(col_names = col_name)
}
# Sélection des colonnes binaires et non binaires
binary_cols <- sapply(df, function(col) all(col %in% c(0, 1))) & !sapply(df, is.character)
quali_cols <- names(df)[binary_cols]
quanti_cols <- setdiff(names(df), quali_cols)
# Assurez-vous d'inclure la colonne de statut
quali_cols <- c(quali_cols, "status")
quanti_cols <- c(quanti_cols, "status")
# Calcul des moyennes pour les variables qualitatives binaires
mean_values_list_quali <- lapply(quali_cols, function(col) {
mean_by_status(df[quali_cols], col)
})
mean_values_df_quali <- bind_rows(mean_values_list_quali)
# Calcul des moyennes pour les variables quantitatives
mean_values_list_quanti <- lapply(quanti_cols, function(col) {
mean_by_status(df[quanti_cols], col)
})
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(caret)
library(tidyr)
library(reshape2)
library(ROCR)
df <- read_csv("dataset_phishing.csv", show_col_types = FALSE)
df <- df[,-1]
df$status <- as.factor(df$status)
df_present <- df
#Extraire les variables qualitatives
v_quali <- vector("logical", length = ncol(df_present) - 1)
for (i in 2:ncol(df_present)) {
v_quali[[i]] <- (length(unique(df_present[[i]])) / sum(!is.na(df_present[[i]]))) < 0.002
}
num_cols <- character()
cat_cols <- character()
for (i in 1:length(v_quali)) {
if (!v_quali[[i]]) {
num_cols <- c(num_cols, names(df_present)[i])
} else {
cat_cols <- c(cat_cols, names(df_present)[i])
}
}
corr <- cor(df_present[num_cols])
ggcorrplot(
corr,
hc.order = TRUE,
type = "full",
outline.color = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"),
show.diag = TRUE,
tl.cex = 7,
tl.srt = 90
)
ggplot(data = melt(df_present[, num_cols]), aes(x = variable, y = value)) +
geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
attach(df)
ggplot(df, aes(x = nb_underscore, y = nb_hyphens )) +
geom_point() +
labs(x = "Nombre tiret du bas", y = "Nombre de tirets") +
ggtitle("Nuage de points : Nombre tiret du bas vs Nombre de tirets")
ggplot(df, aes(x = domain_age, y = ratio_extHyperlinks)) +
geom_point() +
labs(x = "Âge du domaine", y = "Nombre de liens externes") +
ggtitle("Nuage de points : Âge du domaines vs Nombre de liens externes")
max(domain_age)
min(domain_age)
# Nuage de point y = longueur url, x = status
ggplot(df, aes(x = status, y = length_url)) +
geom_point() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Nuage de points : Longueur de l'URL vs Status")
# Boxplot
ggplot(df, aes(x = status, y = log(length_url))) +
geom_boxplot() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Boxplot : Longueur de l'URL vs Status")
set.seed(123)
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- df[indxTrain, ]
DTest <- df[-indxTrain, ]
ctrl <- trainControl(method = "cv", number = 5)
set.seed(123)
k <- c(1:10, seq(12, 19, by = 2), seq(20, 99, by = 5), seq(100, 500, by = 50))
#fit.knn.cv <- train(status ~ .,data = DTrain,method = "knn",trControl = ctrl,tuneGrid = expand.grid(k = k),preProcess = c("center", "scale"),na.action = na.omit)
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.knn.cv.RDATA")
plot(fit.knn.cv)
bestK <- fit.knn.cv$bestTune$k
print(fit.knn.cv$results)
#matrice de confusion
predictions <- predict(fit.knn.cv, newdata = DTest)
confusionMatrix(predictions, DTest$status)
#Sans AIC
fit.lr <- train(status ~ .,
data = DTrain,
method = "glm",
trControl = ctrl,
na.action = na.omit)
print(varImp(fit.lr))
#Avec AIC
#fit.lr.aic <- train(status ~ ., data = DTrain, method = "glmStepAIC", trControl = ctrl, na.action = na.omit)
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.lr.aic.RDATA")
importance <- varImp(fit.lr)$importance
variable_names <- rownames(importance)
importance_values <- importance$Overall
variable_indexes <- match(variable_names, names(DTrain))
important_vars_df <- data.frame(
Variable = variable_names,
Importance = importance_values,
Index = variable_indexes
)
important_vars_df_sorted <- important_vars_df[order(important_vars_df$Importance, decreasing = TRUE), ]
# accuracies_nb <- numeric()
# best_accuracy_nb <- 0
# best_combination_nb <- NULL
#
# for (i in 2:25) {
#   variable_names_nb <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
#   fit.nb_temp <- train(status ~ .,
#                        data = DTrain[, c("status", variable_names_nb)],
#                        method = "nb",
#                        trControl = ctrl)
#   model_accuracy_nb <- max(fit.nb_temp$results$Accuracy)
#   accuracies_nb[i - 1] <- model_accuracy_nb
#
#   if (model_accuracy_nb > best_accuracy_nb) {
#     best_accuracy_nb <- model_accuracy_nb
#     best_combination_nb <- variable_names_nb
#   }
# }
#
# fit.nb <- train(status ~ .,
#                 data = DTrain[, c("status", best_combination_nb)],
#                 method = "nb",
#                 trControl = ctrl)
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.nb.RDATA")
plot(accuracies_nb, type = "l", xlab = "Nombre de variables", ylab = "Précision", main = "Précision en fonction du nombre de variables importantes")
fit.lda = train(status ~ .,
data = DTrain[, -c(9, 60, 62, 64, 69, 72)],
method="lda",
trControl=ctrl)
# accuracy_qda <- numeric()
# best_accuracy_qda <- 0
# best_combination_qda <- NULL
#
# for (i in 2:35) {
#   variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
#
#   fit.qda <- train(status ~ .,
#                    data = DTrain[, c("status", variable_names)],
#                    method = "qda",
#                    trControl = ctrl)
#
#   model_accuracy <- max(fit.qda$results$Accuracy)
#
#   accuracy_qda[i - 1] <- model_accuracy
#
#   if (model_accuracy > best_accuracy_qda) {
#     best_accuracy_qda <- model_accuracy
#     best_combination_qda <- variable_names
#   }
# }
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.qda.RDATA")
plot(accuracies_qda, type = "l", xlab = "Nombre de variables", ylab = "Précision", main = "Précision en fonction du nombre de variables importantes")
# svmGrid_lin <- seq(0.0001, 0.01 ,by = 0.001)
# best_accuracies_svm <- numeric()
# best_accuracy_svm <- 0
# best_combination_svm <- NULL
# best_C_svm <- NULL
#
# for (i in 2:20) {
#   variable_names_svm <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
#   fit.Lin.svm <- train(status ~ .,
#                        data = DTrain[, c("status", variable_names_svm)],
#                        method = "svmLinear",
#                        type = "C-svc",
#                        trControl = ctrl,
#                        tuneGrid = data.frame(.C = svmGrid_lin))
#   max_accuracy <- max(fit.Lin.svm$results$Accuracy)
#   max_C <- fit.Lin.svm$bestTune$.C
#
#   best_accuracies_svm[i - 1] <- max_accuracy
#
#   if (max_accuracy > best_accuracy_svm) {
#     best_accuracy_svm <- max_accuracy
#     best_combination_svm <- variable_names_svm
#     best_C_svm <- max_C
#   }
# }
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.Lin.svm.RDATA")
fit.Lin.svm$bestTune
#Noyau Radial
# svmGrid_quad <- expand.grid(.C = seq(0.0001, 0.01, by = 0.001), .sigma = seq(0.0001, 0.01, by = 0.001))
# best_accuracies_svm_radial <- numeric()
# best_accuracy_svm_radial <- 0
# best_combination_svm_radial <- NULL
# best_params_svm_radial <- NULL
#
# for (i in 2:20) {
#   variable_names_svm_radial <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
#   fit.Quad.svm <- train(status ~ .,
#                         data = DTrain[, c("status", variable_names_svm_radial)],
#                         method = "svmRadial",
#                         type = "C-svc",
#                         trControl = ctrl_temp,
#                         tuneGrid = svmGrid_quad)
#
#   max_accuracy_radial <- max(fit.Quad.svm$results$Accuracy)
#   max_params_radial <- fit.Quad.svm$bestTune
#
#   best_accuracies_svm_radial[i - 1] <- max_accuracy_radial
#
#   if (max_accuracy_radial > best_accuracy_svm_radial) {
#     best_accuracy_svm_radial <- max_accuracy_radial
#     best_combination_svm_radial <- variable_names_svm_radial
#     best_params_svm_radial <- max_params_radial
#   }
# }
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.Quad.svm.RDATA")
plot(fit.Quad.svm)
fit.Quad.svm$bestTune
set.seed(123)
predictionsBestK <- predict(fit.knn.cv, newdata = DTest)
confusionMatrixBestK <- confusionMatrix(predictionsBestK, DTest$status)
print(confusionMatrixBestK$overall['Accuracy'])
set.seed(123)
predictionsBestK <- predict(fit.knn.cv, newdata = DTest, type = "prob")
pred.knn <- prediction(predictionsBestK[,2], DTest$status)
perf.knn <- performance(pred.knn, "tpr", "fpr")
plot(perf.knn)
auc.knn <- performance(pred.knn, "auc")@y.values[[1]]
class.lr <- predict(fit.lr, newdata = DTest)
print(varImp(fit.lr))
class.lr.aic <- predict(fit.lr.aic, newdata = DTest)
confusionMatrixLR <- confusionMatrix(class.lr, DTest$status)
confusionMatrixLRAIC <- confusionMatrix(class.lr.aic, DTest$status)
print(confusionMatrixLR$overall['Accuracy'])
print(confusionMatrixLRAIC$overall['Accuracy'])
class.lr <- predict(fit.lr, newdata = DTest, type = "prob")
class.lr.aic <- predict(fit.lr.aic, newdata = DTest, type = "prob")
pred.lr <- prediction(class.lr[,2], DTest$status)
perf.lr <- performance(pred.lr, "tpr", "fpr")
auc.lr <- performance(pred.lr, "auc")@y.values[[1]]
#Accuracy
class.nb <- predict(fit.nb, newdata = DTest)
confusionMatrixNB <- confusionMatrix(class.nb, DTest$status)
print(confusionMatrixNB$overall['Accuracy'])
pred.nb = predict(fit.nb, newdata=DTest[,c(best_combination_nb)], type = "prob")
pred.nb <- prediction(pred.nb[,2], DTest$status)
perf.nb <- performance(pred.nb, "tpr", "fpr")
auc.nb <- performance(pred.nb, "auc")@y.values[[1]]
class.lda <- predict(fit.lda, newdata = DTest)
confusionMatrixLDA <- confusionMatrix(class.lda, DTest$status)
print(confusionMatrixLDA$overall['Accuracy'])
pred.lda = predict(fit.lda, newdata=DTest[,-c(9, 60, 62, 64, 69, 72, 88)], type = "prob")
pred.lda <- prediction(pred.lda[,2], DTest$status)
perf.lda <- performance(pred.lda, "tpr", "fpr")
plot(perf.lda)
auc.lda <- performance(pred.lda, "auc")@y.values[[1]]
class.qda <- predict(fit.qda, newdata = DTest)
confusionMatrixQDA <- confusionMatrix(class.qda, DTest$status)
print(confusionMatrixQDA$overall['Accuracy'])
pred.qda = predict(fit.qda, newdata=DTest[, best_combination_qda], type = "prob")
pred.qda <- prediction(pred.qda[,2], DTest$status)
perf.qda <- performance(pred.qda, "tpr", "fpr")
plot(perf.qda)
auc.qda <- performance(pred.qda, "auc")@y.values[[1]]
class.Lin.svm <- predict(fit.Lin.svm, newdata = DTest)
confusionMatrixLinSVM <- confusionMatrix(class.Lin.svm, DTest$status)
print(confusionMatrixLinSVM$overall['Accuracy'])
class.Quad.svm <- predict(fit.Quad.svm, newdata = DTest)
confusionMatrixQuadSVM <- confusionMatrix(class.Quad.svm, DTest$status)
print(confusionMatrixQuadSVM$overall['Accuracy'])
models <- c("KNN", "Logistique", "NB", "LDA", "QDA")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'])
auc <- c(auc.knn, auc.lr, auc.nb, auc.lda, auc.qda)
df_models <- data.frame(models, accuracy, sensibilite, specificite, auc)
df_models
legend_labels <- c(
paste("KNN (AUC =", round(auc.knn, 3), ")"),
paste("Logistique (AUC =", round(auc.lr, 3), ")"),
paste("NB (AUC =", round(auc.nb, 3), ")"),
paste("LDA (AUC =", round(auc.lda, 3), ")"),
paste("QDA (AUC =", round(auc.qda, 3), ")")
)
plot(perf.knn, col = "red", main = "Courbes ROC", lty = 1)
plot(perf.lr, col = "blue", add = TRUE, lty = 2)
plot(perf.nb, col = "green", add = TRUE, lty = 3)
plot(perf.lda, col = "orange", add = TRUE, lty = 4)
plot(perf.qda, col = "purple", add = TRUE, lty = 5)
legend(0.5, 0.5, legend = legend_labels, col = c("red", "blue", "green", "orange", "purple"), lty = c(1, 2, 3, 4, 5), cex = 0.8)
models <- c("KNN", "Logistique", "NB", "LDA", "QDA", "SVM Linéaire", "SVM Quadratique")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'], confusionMatrixLinSVM$overall['Accuracy'], confusionMatrixQuadSVM$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'], confusionMatrixLinSVM$byClass['Sensitivity'], confusionMatrixQuadSVM$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'], confusionMatrixLinSVM$byClass['Specificity'], confusionMatrixQuadSVM$byClass['Specificity'])
auc <- c(auc.knn, auc.lr, auc.nb, auc.lda, auc.qda, auc.lin.svm, auc.quad.svm)
models <- c("KNN", "Logistique", "NB", "LDA", "QDA", "SVM Linéaire", "SVM Quadratique")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'], confusionMatrixLinSVM$overall['Accuracy'], confusionMatrixQuadSVM$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'], confusionMatrixLinSVM$byClass['Sensitivity'], confusionMatrixQuadSVM$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'], confusionMatrixLinSVM$byClass['Specificity'], confusionMatrixQuadSVM$byClass['Specificity'])
sensibilite
models <- c("KNN", "Logistique", "NB", "LDA", "QDA", "SVM Linéaire", "SVM Quadratique")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'], confusionMatrixLinSVM$overall['Accuracy'], confusionMatrixQuadSVM$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'], confusionMatrixLinSVM$byClass['Sensitivity'], confusionMatrixQuadSVM$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'], confusionMatrixLinSVM$byClass['Specificity'], confusionMatrixQuadSVM$byClass['Specificity'])
auc <- c(auc.knn, auc.lr, auc.nb, auc.lda, auc.qda, auc.lin.svm, auc.quad.svm)
class.Lin.svm <- predict(fit.Lin.svm, newdata = DTest)
confusionMatrixLinSVM <- confusionMatrix(class.Lin.svm, DTest$status)
print(confusionMatrixLinSVM$overall['Accuracy'])
pred.lin.svm = predict(fit.Lin.svm, newdata=DTest[, best_combination_svm], type = "prob")
pred.lin.svm <- prediction(pred.lin.svm[,2], DTest$status)
legend_labels <- c(
paste("KNN (AUC =", round(auc.knn, 3), ")"),
paste("Logistique (AUC =", round(auc.lr, 3), ")"),
paste("NB (AUC =", round(auc.nb, 3), ")"),
paste("LDA (AUC =", round(auc.lda, 3), ")"),
paste("QDA (AUC =", round(auc.qda, 3), ")")
)
plot(perf.knn, col = "red", main = "Courbes ROC", lty = 1, xlim = c(0, 0.2), ylim = c(0.8, 1))
plot(perf.lr, col = "blue", add = TRUE, lty = 2)
plot(perf.nb, col = "green", add = TRUE, lty = 3)
plot(perf.lda, col = "orange", add = TRUE, lty = 4)
plot(perf.qda, col = "purple", add = TRUE, lty = 5)
legend(0.12, 0.88, legend = legend_labels, col = c("red", "blue", "green", "orange", "purple"), lty = c(1, 2, 3, 4, 5), cex = 0.8)
models <- c("KNN", "Logistique", "NB", "LDA", "QDA")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'])
auc <- c(auc.knn, auc.lr, auc.nb, auc.lda, auc.qda)
df_models <- data.frame(models, accuracy, sensibilite, specificite, auc)
df_models
df_models
round(df_models, 2)
View(df_models)
models <- c("KNN", "Logistique", "NB", "LDA", "QDA", "SVM Linéaire", "SVM Quadratique")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'], confusionMatrixLinSVM$overall['Accuracy'], confusionMatrixQuadSVM$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'], confusionMatrixLinSVM$byClass['Sensitivity'], confusionMatrixQuadSVM$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'], confusionMatrixLinSVM$byClass['Specificity'], confusionMatrixQuadSVM$byClass['Specificity'])
auc <- c(auc.knn, auc.lr, auc.nb, auc.lda, auc.qda)
df_models <- data.frame(models, accuracy, sensibilite, specificite, auc)
models <- c("KNN", "Logistique", "NB", "LDA", "QDA", "SVM Linéaire", "SVM Quadratique")
accuracy <- c(confusionMatrixBestK$overall['Accuracy'], confusionMatrixLR$overall['Accuracy'], confusionMatrixNB$overall['Accuracy'], confusionMatrixLDA$overall['Accuracy'], confusionMatrixQDA$overall['Accuracy'], confusionMatrixLinSVM$overall['Accuracy'], confusionMatrixQuadSVM$overall['Accuracy'])
sensibilite <- c(confusionMatrixBestK$byClass['Sensitivity'], confusionMatrixLR$byClass['Sensitivity'], confusionMatrixNB$byClass['Sensitivity'], confusionMatrixLDA$byClass['Sensitivity'], confusionMatrixQDA$byClass['Sensitivity'], confusionMatrixLinSVM$byClass['Sensitivity'], confusionMatrixQuadSVM$byClass['Sensitivity'])
specificite <- c(confusionMatrixBestK$byClass['Specificity'], confusionMatrixLR$byClass['Specificity'], confusionMatrixNB$byClass['Specificity'], confusionMatrixLDA$byClass['Specificity'], confusionMatrixQDA$byClass['Specificity'], confusionMatrixLinSVM$byClass['Specificity'], confusionMatrixQuadSVM$byClass['Specificity'])
auc <- c(auc.knn, auc.lr, auc.nb, auc.lda, auc.qda, NA, NA)
df_models <- data.frame(models, accuracy, sensibilite, specificite, auc)
df_models
legend_labels <- c(
paste("KNN (AUC =", round(auc.knn, 3), ")"),
paste("Logistique (AUC =", round(auc.lr, 3), ")"),
paste("NB (AUC =", round(auc.nb, 3), ")"),
paste("LDA (AUC =", round(auc.lda, 3), ")"),
paste("QDA (AUC =", round(auc.qda, 3), ")")
)
plot(perf.knn, col = "red", main = "Courbes ROC", lty = 1)
plot(perf.lr, col = "blue", add = TRUE, lty = 2)
plot(perf.nb, col = "green", add = TRUE, lty = 3)
plot(perf.lda, col = "orange", add = TRUE, lty = 4)
plot(perf.qda, col = "purple", add = TRUE, lty = 5)
legend(0.5, 0.5, legend = legend_labels, col = c("red", "blue", "green", "orange", "purple"), lty = c(1, 2, 3, 4, 5), cex = 0.8)
legend_labels <- c(
paste("KNN (AUC =", round(auc.knn, 3), ")"),
paste("Logistique (AUC =", round(auc.lr, 3), ")"),
paste("NB (AUC =", round(auc.nb, 3), ")"),
paste("LDA (AUC =", round(auc.lda, 3), ")"),
paste("QDA (AUC =", round(auc.qda, 3), ")")
)
plot(perf.knn, col = "red", main = "Courbes ROC", lty = 1, xlim = c(0, 0.2), ylim = c(0.8, 1))
plot(perf.lr, col = "blue", add = TRUE, lty = 2)
plot(perf.nb, col = "green", add = TRUE, lty = 3)
plot(perf.lda, col = "orange", add = TRUE, lty = 4)
plot(perf.qda, col = "purple", add = TRUE, lty = 5)
legend(0.11, 0.88, legend = legend_labels, col = c("red", "blue", "green", "orange", "purple"), lty = c(1, 2, 3, 4, 5), cex = 0.8)
df_models
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(.data[[col_name]], na.rm = TRUE))
}
mean_values_list_cat <- list()
for (col in cat_cols) {
mean_values_list_cat[[col]] <- mean_by_status(df_present, col)
}
mean_values_df_cat <- do.call(rbind, mean_values_list_cat)
mean_values_df_cat$col_names <- rownames(mean_values_df_cat)
mean_values_df_cat <- mean_values_df_cat[mean_values_df_cat$mean_value > 0.1 | mean_values_df_cat$mean_value < -0.1,]
mean_values_df_cat <- mean_values_df_cat[!is.na(mean_values_df_cat$mean_value), ]
ggplot(mean_values_df_cat, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables qualitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
View(df)
