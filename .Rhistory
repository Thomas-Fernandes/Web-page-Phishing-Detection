fit.qda
# Sélectionner les noms des variables des 20 premiers index
top_20_variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:20]]
# Ajuster le modèle QDA en incluant la variable cible 'status'
fit.qda <- train(status ~ .,
data = DTrain[, c("status", top_20_variable_names)],
method = "qda",
trControl = ctrl)
fit.qda
# Sélectionner les noms des variables des 20 premiers index
top_20_variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:30]]
# Ajuster le modèle QDA en incluant la variable cible 'status'
fit.qda <- train(status ~ .,
data = DTrain[, c("status", top_20_variable_names)],
method = "qda",
trControl = ctrl)
fit.qda
fit.qda
# Sélectionner les noms des variables des 20 premiers index
top_20_variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:10]]
# Ajuster le modèle QDA en incluant la variable cible 'status'
fit.qda <- train(status ~ .,
data = DTrain[, c("status", top_20_variable_names)],
method = "qda",
trControl = ctrl)
fit.qda
# Initialiser une variable pour stocker la meilleure précision et la meilleure combinaison de variables
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:20) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Initialiser une variable pour stocker la meilleure précision et la meilleure combinaison de variables
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:30) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Créer un dataframe pour enregistrer les résultats
results_df <- data.frame(NumberOfVariables = integer(),
Indices = I(list()),
Accuracy = numeric())
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:20) {
# Sélectionner les indices des i premières variables importantes
indices <- important_vars_df_sorted$Index[1:i]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", names(DTrain)[indices])],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Ajouter les résultats dans le dataframe
results_df <- rbind(results_df, list(NumberOfVariables = i, Indices = list(indices), Accuracy = model_accuracy))
}
# Initialiser un vecteur pour stocker les précisions de chaque combinaison
accuracies <- numeric(19)  # 19 combinaisons possibles (de 2 à 20)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:20) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher les précisions pour chaque nombre de variables
print(accuracies)
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Afficher les précisions pour chaque nombre de variables
plot(accuracies)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:30) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher les précisions pour chaque nombre de variables
plot(accuracies)
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:40) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher les précisions pour chaque nombre de variables
plot(accuracies)
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:40) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qdaAic",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:40) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher les précisions pour chaque nombre de variables
plot(accuracies)
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:35) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
# Afficher les précisions pour chaque nombre de variables
plot(accuracies)
# Afficher la meilleure précision et la combinaison de variables correspondante
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison
best_accuracy <- 0
best_combination <- NULL
# Tester toutes les combinaisons de 2 à 20 variables
for (i in 2:35) {
# Sélectionner les noms des i premières variables importantes
variable_names <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle QDA avec cette combinaison de variables
fit.qda <- train(status ~ .,
data = DTrain[, c("status", variable_names)],
method = "qda",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy <- max(fit.qda$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies[i - 1] <- model_accuracy
# Comparer avec la meilleure précision trouvée jusqu'à présent
if (model_accuracy > best_accuracy) {
best_accuracy <- model_accuracy
best_combination <- variable_names
}
}
plot(accuracies, type = "l", xlab = "Nombre de variables", ylab = "Précision", main = "Précision en fonction du nombre de variables")
print(paste("Meilleure précision:", best_accuracy))
print("Meilleure combinaison de variables:")
print(best_combination)
# Créer le graphique
plot(accuracies, type = "l", xlab = "Nombre de variables importantes", ylab = "Précision", main = "Précision en fonction du nombre de variables")
# Ajouter un encadré avec la meilleure précision
best_accuracy_text <- paste("Meilleure précision:", round(best_accuracy, 4))  # Arrondir pour une meilleure lisibilité
text(x = 15, y = min(accuracies), labels = best_accuracy_text, pos = 4)  # Changer 'x' et 'y' selon le besoin
plot(accuracies, type = "l", xlab = "Nombre de variables importantes", ylab = "Précision", main = "Précision en fonction du nombre de variables", add = TRUE)
legend("bottomright", legend = paste("Meilleure précision:", round(best_accuracy, 4)))
plot(accuracies, type = "l", xlab = "Nombre de variables importantes", ylab = "Précision", main = "Précision en fonction du nombre de variables")
plot(accuracies, type = "l", xlab = "Nombre de variables", ylab = "Précision", main = "Précision en fonction du nombre de variables importantes")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(caret)
library(tidyr)
library(reshape2)
library(plotROC)
library(ROCR)
df <- read_csv("dataset_phishing.csv", show_col_types = FALSE)
df <- df[,-1]
df$status <- as.factor(df$status)
df_present <- df
#Extraire les variables qualitatives
v_quali <- vector("logical", length = ncol(df_present) - 1)
for (i in 2:ncol(df_present)) {
v_quali[[i]] <- (length(unique(df_present[[i]])) / sum(!is.na(df_present[[i]]))) < 0.002
}
num_cols <- character()
cat_cols <- character()
for (i in 1:length(v_quali)) {
if (!v_quali[[i]]) {
num_cols <- c(num_cols, names(df_present)[i])
} else {
cat_cols <- c(cat_cols, names(df_present)[i])
}
}
corr <- cor(df_present[num_cols])
ggcorrplot(
corr,
hc.order = TRUE,
type = "full",
outline.color = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"),
show.diag = TRUE,
tl.cex = 7,
tl.srt = 90
)
ggplot(data = melt(df_present[, num_cols]), aes(x = variable, y = value)) +
geom_boxplot() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
attach(df)
ggplot(df, aes(x = log(length_url), y = log(domain_age))) +
geom_point() +
labs(x = "Longueur de l'URL", y = "Âge du domaine") +
ggtitle("Nuage de points : Longueur de l'URL vs Âge du domaine")
max(domain_age)
min(domain_age)
# Nuage de point y = longueur url, x = status
ggplot(df, aes(x = status, y = length_url)) +
geom_point() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Nuage de points : Longueur de l'URL vs Status")
# Boxplot
ggplot(df, aes(x = status, y = log(length_url))) +
geom_boxplot() +
labs(x = "Status", y = "Longueur de l'URL") +
ggtitle("Boxplot : Longueur de l'URL vs Status")
mean_by_status <- function(df, col_name) {
df %>%
group_by(status) %>%
summarise(mean_value = mean(.data[[col_name]], na.rm = TRUE))
}
mean_values_list_cat <- list()
for (col in cat_cols) {
mean_values_list_cat[[col]] <- mean_by_status(df_present, col)
}
mean_values_df_cat <- do.call(rbind, mean_values_list_cat)
mean_values_df_cat$col_names <- rownames(mean_values_df_cat)
mean_values_df_cat <- mean_values_df_cat[mean_values_df_cat$mean_value > 0.1 | mean_values_df_cat$mean_value < -0.1,]
mean_values_df_cat <- mean_values_df_cat[!is.na(mean_values_df_cat$mean_value), ]
ggplot(mean_values_df_cat, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables qualitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
mean_values_list_num <- list()
for (col in num_cols) {
if (col != "web_traffic" && col != "domain_age" && col != "domain_registration_length") {
mean_values_list_num[[col]] <- mean_by_status(df_present, col)
}
}
mean_values_df_num <- do.call(rbind, mean_values_list_num)
mean_values_df_num$col_names <- rownames(mean_values_df_num)
mean_values_df_num <- mean_values_df_num[mean_values_df_num$mean_value > 0.3 | mean_values_df_num$mean_value < -0.3,]
mean_values_df_num <- mean_values_df_num[!is.na(mean_values_df_num$mean_value), ]
ggplot(mean_values_df_num, aes(x = col_names, y = mean_value, fill = status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Variables", y = "Moyenne", title = "Moyenne des variables quantitatives par statut") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_manual(values = c("#E46726", "#6D9EC1"))
set.seed(123)
indxTrain <- createDataPartition(df$status, p = 0.75, list = FALSE)
DTrain <- df[indxTrain, ]
DTest <- df[-indxTrain, ]
ctrl <- trainControl(method = "cv", number = 5)
set.seed(123)
k <- c(1:10, seq(12, 19, by = 2), seq(20, 99, by = 5), seq(100, 500, by = 50))
#fit.knn.cv <- train(status ~ .,data = DTrain,method = "knn",trControl = ctrl,tuneGrid = expand.grid(k = k),preProcess = c("center", "scale"),na.action = na.omit)
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.knn.cv.RDATA")
plot(fit.knn.cv)
bestK <- fit.knn.cv$bestTune$k
print(fit.knn.cv$results)
#Sans AIC
fit.lr <- train(status ~ .,
data = DTrain,
method = "glm",
trControl = ctrl,
na.action = na.omit)
print(varImp(fit.lr))
#Avec AIC
#fit.lr.aic <- train(status ~ ., data = DTrain, method = "glmStepAIC", trControl = ctrl, na.action = na.omit)
load("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection/fit.lr.aic.RDATA")
fit.nb = train(status ~ ., data = DTrain, method = "nb", trControl = ctrl)
# Initialiser un vecteur pour stocker les précisions de chaque combinaison
accuracies_nb <- numeric(19)  # 19 combinaisons possibles (de 2 à 20)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison pour le modèle bayésien naïf
best_accuracy_nb <- 0
best_combination_nb <- NULL
# Tester toutes les combinaisons de 2 à 20 variables pour le modèle bayésien naïf
for (i in 2:20) {
# Sélectionner les noms des i premières variables importantes
variable_names_nb <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle bayésien naïf avec cette combinaison de variables
fit.nb <- train(status ~ .,
data = DTrain[, c("status", variable_names_nb)],
method = "nb",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy_nb <- max(fit.nb$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies_nb[i - 1] <- model_accuracy_nb
# Comparer avec la meilleure précision trouvée jusqu'à présent pour le modèle bayésien naïf
if (model_accuracy_nb > best_accuracy_nb) {
best_accuracy_nb <- model_accuracy_nb
best_combination_nb <- variable_names_nb
}
}
importance <- varImp(fit.lr)$importance
variable_names <- rownames(importance)
importance_values <- importance$Overall
variable_indexes <- match(variable_names, names(DTrain))
important_vars_df <- data.frame(
Variable = variable_names,
Importance = importance_values,
Index = variable_indexes
)
important_vars_df_sorted <- important_vars_df[order(important_vars_df$Importance, decreasing = TRUE), ]
# Initialiser une variable pour la meilleure précision et la meilleure combinaison pour le modèle bayésien naïf
best_accuracy_nb <- 0
best_combination_nb <- NULL
# Tester toutes les combinaisons de 2 à 20 variables pour le modèle bayésien naïf
for (i in 2:10) {
# Sélectionner les noms des i premières variables importantes
variable_names_nb <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle bayésien naïf avec cette combinaison de variables
fit.nb <- train(status ~ .,
data = DTrain[, c("status", variable_names_nb)],
method = "nb",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy_nb <- max(fit.nb$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies_nb[i - 1] <- model_accuracy_nb
# Comparer avec la meilleure précision trouvée jusqu'à présent pour le modèle bayésien naïf
if (model_accuracy_nb > best_accuracy_nb) {
best_accuracy_nb <- model_accuracy_nb
best_combination_nb <- variable_names_nb
}
}
# Afficher les précisions pour chaque nombre de variables pour le modèle bayésien naïf
print(accuracies_nb)
# Afficher la meilleure précision et la combinaison de variables correspondante pour le modèle bayésien naïf
print(paste("Meilleure précision Naive Bayes:", best_accuracy_nb))
print("Meilleure combinaison de variables pour Naive Bayes:")
print(best_combination_nb)
# Afficher les précisions pour chaque nombre de variables pour le modèle bayésien naïf
plot(accuracies_nb)
# Initialiser un vecteur pour stocker les précisions de chaque combinaison
accuracies_nb <- numeric(19)  # 19 combinaisons possibles (de 2 à 20)
# Initialiser une variable pour la meilleure précision et la meilleure combinaison pour le modèle bayésien naïf
best_accuracy_nb <- 0
best_combination_nb <- NULL
# Tester toutes les combinaisons de 2 à 20 variables pour le modèle bayésien naïf
for (i in 2:20) {
# Sélectionner les noms des i premières variables importantes
variable_names_nb <- names(DTrain)[important_vars_df_sorted$Index[1:i]]
# Ajuster le modèle bayésien naïf avec cette combinaison de variables
fit.nb_temp <- train(status ~ .,
data = DTrain[, c("status", variable_names_nb)],
method = "nb",
trControl = ctrl)
# Obtenir l'accuracy du modèle
model_accuracy_nb <- max(fit.nb_temp$results$Accuracy)
# Stocker l'accuracy dans le vecteur
accuracies_nb[i - 1] <- model_accuracy_nb
# Comparer avec la meilleure précision trouvée jusqu'à présent pour le modèle bayésien naïf
if (model_accuracy_nb > best_accuracy_nb) {
best_accuracy_nb <- model_accuracy_nb
best_combination_nb <- variable_names_nb
}
}
# Entraîner le modèle bayésien naïf sur la meilleure combinaison de variables
fit.nb <- train(status ~ .,
data = DTrain[, c("status", best_combination_nb)],
method = "nb",
trControl = ctrl)
# Afficher les précisions pour chaque nombre de variables pour le modèle bayésien naïf
print(accuracies_nb)
# Afficher la meilleure précision et la combinaison de variables correspondante pour le modèle bayésien naïf
print(paste("Meilleure précision Naive Bayes:", best_accuracy_nb))
print("Meilleure combinaison de variables pour Naive Bayes:")
print(best_combination_nb)
# Afficher les précisions pour chaque nombre de variables pour le modèle bayésien naïf
plot(accuracies_nb)
