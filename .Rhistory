freq.pulmonaire <- table(tabac$probleme_pulmonaire)
# Créer le graphique en secteurs (pie chart)
# Créer le graphique en secteurs (pie chart)
pie(freq.fumeur, labels = paste0(labels, ": ", freq.fumeur), main = "Fumeur")
View(pie_fumeur)
View(tabac)
freq.fumeur
library(readr)
tabac <- read_csv("tabac.csv", show_col_types = FALSE)
head(tabac)
str(tabac)
summary(tabac)
tabac$fumeur <- ifelse(tabac$tabagisme_passif == TRUE, 1, 0)
#Calculer les fréquences observées pour les modalités des variables "fumeur" et "problème pulmonaire"
freq.fumeur <- table(tabac$fumeur)
freq.pulmonaire <- table(tabac$probleme_pulmonaire)
# Créer le graphique en secteurs (pie chart)
# Créer le graphique en secteurs (pie chart)
pie(freq.fumeur, labels = paste0(labels, ": ", freq.fumeur, "%"), main = "Fumeur")
library(readr)
tabac <- read_csv("tabac.csv", show_col_types = FALSE)
head(tabac)
str(tabac)
summary(tabac)
tabac$fumeur <- ifelse(tabac$tabagisme_passif == TRUE, 1, 0)
#Calculer les fréquences observées pour les modalités des variables "fumeur" et "problème pulmonaire"
freq.fumeur <- table(tabac$fumeur)
freq.pulmonaire <- table(tabac$probleme_pulmonaire)
pie(freq.fumeur,
labels = paste0(labels, " : ", freq.fumeur, "%"),
main = "Fumeur")
pie(freq.pulmonaire,
labels = paste0(labels, " : ", freq.pulmonaire, "%"),
main = "Problème pulmonaire")
knitr::opts_chunk$set(echo = TRUE)
restaurant <- data.frame(
nb.convives = c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
)
population <- nrow(restaurant)
effectif.total <- sum(restaurant$nb.convives)
#La variable étudiée est le nombre de convives elle est de type quantitative discrète
mode <- max(restaurant$nb.convives)
mediane <- median(restaurant$nb.convives)
moyenne <- mean(restaurant$nb.convives)
restaurant$nb.convives <- factor(restaurant$nb.convives, levels = 1:6)
effectifs <- table(restaurant$nb.convives)
barplot(effectifs,
main = "Distribution du nombre de convives",
xlab = "Nombre de convives",
ylab = "Effectifs",
ylim = c(0, 6),
space = 20)
box()
library(readr)
tabac <- read_csv("tabac.csv", show_col_types = FALSE)
head(tabac)
str(tabac)
summary(tabac)
tabac$fumeur <- ifelse(tabac$tabagisme_passif == TRUE, 1, 0)
#Calculer les fréquences observées pour les modalités des variables "fumeur" et "problème pulmonaire"
freq.fumeur <- table(tabac$fumeur)
freq.pulmonaire <- table(tabac$probleme_pulmonaire)
pie(freq.fumeur,
labels = paste0(labels, " : ", freq.fumeur, "%"),
main = "Fumeur")
convives <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
mod <- mode(convives)
restaurant <- data.frame(
nb.convives = c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
)
population <- nrow(restaurant)
effectif.total <- sum(restaurant$nb.convives)
#La variable étudiée est le nombre de convives elle est de type quantitative discrète
mode <- max(restaurant$nb.convives)
mediane <- median(restaurant$nb.convives)
moyenne <- mean(restaurant$nb.convives)
restaurant$nb.convives <- factor(restaurant$nb.convives, levels = 1:6)
effectifs <- table(restaurant$nb.convives)
barplot(effectifs,
main = "Distribution du nombre de convives",
xlab = "Nombre de convives",
ylab = "Effectifs",
ylim = c(0, 6),
space = 20)
box()
restaurant <- data.frame(
nb.convives = c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
)
population <- nrow(restaurant)
effectif.total <- sum(restaurant$nb.convives)
#La variable étudiée est le nombre de convives elle est de type quantitative discrète
#Le mode est 2, il correspond à la variable avec l'effectif le plus grand
mediane <- median(restaurant$nb.convives)
moyenne <- mean(restaurant$nb.convives)
restaurant$nb.convives <- factor(restaurant$nb.convives, levels = 1:6)
effectifs <- table(restaurant$nb.convives)
barplot(effectifs,
main = "Distribution du nombre de convives",
xlab = "Nombre de convives",
ylab = "Effectifs",
ylim = c(0, 6),
space = 20)
box()
restaurant <- data.frame(
nb.convives = c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
)
population <- nrow(restaurant)
effectif.total <- sum(restaurant$nb.convives)
#La variable étudiée est le nombre de convives elle est de type quantitative discrète
#Le mode est 2, il correspond à la variable avec l'effectif le plus grand
mediane <- median(restaurant$nb.convives)
moyenne <- mean(restaurant$nb.convives)
restaurant$nb.convives <- factor(restaurant$nb.convives, levels = 1:max(restaurant$nb.convives))
effectifs <- table(restaurant$nb.convives)
barplot(effectifs,
main = "Distribution du nombre de convives",
xlab = "Nombre de convives",
ylab = "Effectifs",
ylim = c(0, 6),
space = 20)
box()
restaurant <- data.frame(
nb.convives = c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
)
population <- nrow(restaurant)
effectif.total <- sum(restaurant$nb.convives)
#La variable étudiée est le nombre de convives elle est de type quantitative discrète
#Le mode est 2, il correspond à la variable avec l'effectif le plus grand
mediane <- median(restaurant$nb.convives)
moyenne <- mean(restaurant$nb.convives)
restaurant$nb.convives <- factor(restaurant$nb.convives, levels = 1:max(restaurant$nb.convives))
effectifs <- table(restaurant$nb.convives)
barplot(effectifs,
main = "Distribution du nombre de convives",
xlab = "Nombre de convives",
ylab = "Effectifs",
ylim = c(0, 6),
space = 20)
box()
effectifs
test <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
test <- factor(test, levels = 1:6)
test_2 <- table(test)
test_2
restaurant <- data.frame(
nb.convives = c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
)
population <- nrow(restaurant)
effectif.total <- sum(restaurant$nb.convives)
#La variable étudiée est le nombre de convives elle est de type quantitative discrète
#Le mode est 2, il correspond à la variable avec l'effectif le plus grand
mediane <- median(restaurant$nb.convives)
moyenne <- mean(restaurant$nb.convives)
restaurant$nb.convives <- factor(restaurant$nb.convives, levels = 1:max(restaurant$nb.convives))
effectifs <- table(restaurant$nb.convives)
barplot(effectifs,
main = "Distribution du nombre de convives",
xlab = "Nombre de convives",
ylab = "Effectifs",
ylim = c(0, 6),
space = 20)
box()
convives <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
convives <- factor(convives, levels = 1:max(convives))
eff_conv <- table(convives)
convives <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
convives <- factor(convives, levels = 1:max(convives))
eff_conv <- table(convives)
eff_conv
convives <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
convives <- table(factor(convives, levels = 1:max(convives)))
convives
convives <- c(1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 6)
convives <- table(factor(convives, levels = 1:max(convives)))
convives
#Charger le fichier trauatisme.txt
traumatisme <- read.table("traumatisme.txt", header = TRUE)
head(traumatisme)
#Mettre les variables Sexe et Accident en type qualitatif avec as.factor
traumatisme$Sexe <- as.factor(traumatisme$Sexe)
traumatisme$Accident <- as.factor(traumatisme$Accident)
View(traumatisme)
traumatisme <- read.table("traumatisme.txt", header = TRUE)
head(traumatisme)
View(traumatisme)
#Charger le fichier trauatisme.txt
traumatisme <- read.table("traumatisme.txt", header = TRUE)
head(traumatisme)
#Mettre les variables Sexe et Accident en type qualitatif avec as.factor
traumatisme$Sexe <- as.factor(traumatisme$Sexe)
traumatisme$Accident <- as.factor(traumatisme$Accident)
saveRDS(restaurant, file = "Restaurant.RDATA")
traumatisme <- read.table("traumatisme.txt", header = TRUE)
head(traumatisme)
View(traumatisme)
PtTourn.test <- function (vec)
{
n <- length(vec)
nT <- 0
for (i in 2:(n-1)){
if (((vec[i] > vec[i-1]) & (vec[i] > vec[i+1])) | ( (vec[i] < vec[i-1])
& (vec[i] < vec[i+1])))
{nT <- nT+1}
}
Tobs <- ( nT - 2*(n-2)/3 ) / sqrt( (16*n-29)/90 )
p <- 2 * (1- pnorm(abs(Tobs)))
res <- c(n,nT,Tobs,p)
names(res) <- c("n","nT","stat"," p-valeur")
return(res)
}
set.seed(345678)
x <- rnorm(100)
plot(bb, type="l")
set.seed(345678)
x <- rnorm(100)
plot(x, type="l")
plot(density(bb))
set.seed(345678)
x <- rnorm(100)
plot(x, type="l")
plot(density(x))
y <- ts(x)
plot(y)
acf(y)
library(tseries)
kpss.test(y)
adf.test(y)
PtTourn.test <- function (vec)
{
n <- length(vec)
nT <- 0
for (i in 2:(n-1)){
if (((vec[i] > vec[i-1]) & (vec[i] > vec[i+1])) | ( (vec[i] < vec[i-1])
& (vec[i] < vec[i+1])))
{nT <- nT+1}
}
Tobs <- ( nT - 2*(n-2)/3 ) / sqrt( (16*n-29)/90 )
p <- 2 * (1- pnorm(abs(Tobs)))
res <- c(n,nT,Tobs,p)
names(res) <- c("n","nT","stat"," p-valeur")
return(res)
}
PtTourn.test <- function (vec)
{
n <- length(vec)
nT <- 0
for (i in 2:(n-1)){
if (((vec[i] > vec[i-1]) & (vec[i] > vec[i+1])) | ( (vec[i] < vec[i-1])
& (vec[i] < vec[i+1])))
{nT <- nT+1}
}
Tobs <- ( nT - 2*(n-2)/3 ) / sqrt( (16*n-29)/90 )
p <- 2 * (1- pnorm(abs(Tobs)))
res <- c(n,nT,Tobs,p)
names(res) <- c("n","nT","stat"," p-valeur")
return(res)
}
set.seed(12345)
y = rnorm(100)
PtTourn.test(y)
library(kernlab)
data(spam)
attach(spam)
dim(spam)
summary(spam)
apply(spam[,-58], 2, median)
apply(spam[,-58], 2, quantile, probs = 0,75)
library(reshape2)
library(ggplot2)
ggplot(data = melt(spam[, -58]), aes(variable, value)) +
geom_boxplot()
ggplot(data = spam, aes(x = type, y = you, fill = type)) +
geom_boxplot()
ggplot(data = spam, aes(x = type, y = credit, fill = type)) +
geom_boxplot()
#Paramètres de controle
ctrl <- trainControl(method = "none")
library(reshape2)
library(ggplot2)
ggplot(data = melt(spam[, -58]), aes(variable, value)) +
geom_boxplot()
ggplot(data = spam, aes(x = type, y = you, fill = type)) +
geom_boxplot()
ggplot(data = spam, aes(x = type, y = credit, fill = type)) +
geom_boxplot()
prop.table(table(type))
library(caret)
set.seed(100)
indxTrain <- createDataPartition(spam$type, p = 0.75, list = FALSE)
Dtrain <- spam[indxTrain,]
Dtest <- spam[-indxTrain,]
#Fréquence des classus sur l'échantillon d'apprentissage et test
print(prop.table(table(Dtrain$type)))
print(prop.table(table(Dtest$type)))
#Paramètres de controle
ctrl <- trainControl(method = "none")
#Apprentissage par régression logistique
fit.lr <- train(type ~ .,
data = Dtrain,
method = "glm",
trControl = ctrl)
print(fit.lr)
summary(fit.lr$finalModel)
print(varImp(fit.lr))
ctrl = trainControl("none")
fit.lr.aic = train(type ~ .,
data = Dtrain,
method = "glmStepAIC",
trControl = ctrl,
direction = "forward")
score.lr = predict(fit.lr.aic,
newdata = Dtest,
type = "prob")
tab = table(data = class.lr, reference = Dtest$type)
library(plotROC)
g = ggplot(score.lr,
aes(m = spam,
d = factor(Dtest$type, levels = c("nonspam","spam")))) +
geom_roc(n.cuts = 20) +
coord_equal() +
style_roc()
indxTrain = createDataPartition(spam$type, p = 0.75, list = FALSE)
Dsub = spam[indxTrain,]
Dtest = spam[-indxTrain,]
ctrl = trainControl(method = "none")
fit.knn = train(type ~ ., data = Dsub, method = "knn",
trControl = ctrl, tuneGrid = data.frame(k = 5),
preProcess = c("center","scale"))
fit.lr = train(type ~ ., data = Dsub, method = "glm",
trControl = ctrl, preProcess = c("center","scale"))
score.knn = predict(fit.knn, newdata = Dtest,type = "prob")
score.lr = predict(fit.lr, newdata = Dtest,type = "prob")
score.data = cbind(Dtest$type, score.knn["spam"], score.lr["spam"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data, "type.test", c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
#Précision des deux modèles
#On fait des classes pour pouvoir comparer les deux modèles
class.knn = predict(fit.knn, newdata = Dtest)
class.lr = predict(fit.lr, newdata = Dtest)
#On crée une table de confusion pour chaque modèle
tab.knn = table(data = class.knn, reference = Dtest$type)
tab.lr = table(data = class.lr, reference = Dtest$type)
#On crée une matrice de confusion pour chaque modèle
mat.knn = confusionMatrix(tab.knn, positive = "spam")
mat.lr = confusionMatrix(tab.lr, positive = "spam")
#On affiche les taux de vrais positifs et de vrais négatifs pour chaque modèle
mat.knn$byClass[c("Specificity","Sensitivity")]
mat.lr$byClass[c("Specificity","Sensitivity")]
#On affiche la specificity
mat.knn$overall["Accuracy"]
mat.lr$overall["Accuracy"]
#AUC
calc_auc(g)$AUC
#AUC
calc_auc(g)$AUC
#On met tous les résultats dans un même tableau
tabbb = matrix(c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"],mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"],mat.knn$byClass["Sensitivity"],mat.lr$byClass["Sensitivity"],calc_auc(g)$AUC),nrow = 4,ncol = 2)
View(tabbb)
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = c(calc_auc(g)$AUC,calc_auc(g.logit)$AUC),
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = c(calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
View(tabb)
set.seed(100
)
indxTrain = createDataPartition(spam$type, p = 0.75, list = FALSE)
Dsub = spam[indxTrain,]
Dtest = spam[-indxTrain,]
ctrl = trainControl(method = "none")
fit.knn = train(type ~ ., data = Dsub, method = "knn",
trControl = ctrl, tuneGrid = data.frame(k = 5),
preProcess = c("center","scale"))
fit.lr = train(type ~ ., data = Dsub, method = "glm",
trControl = ctrl, preProcess = c("center","scale"))
score.knn = predict(fit.knn, newdata = Dtest,type = "prob")
score.lr = predict(fit.lr, newdata = Dtest,type = "prob")
score.data = cbind(Dtest$type, score.knn["spam"], score.lr["spam"])
colnames(score.data) = c("type.test","knn","logit")
score.data <- melt_roc(score.data, "type.test", c("knn","logit"))
g=ggplot(score.data, aes(m = M,d = D,color = name)) + geom_roc()
g
#Précision des deux modèles
#On fait des classes pour pouvoir comparer les deux modèles
class.knn = predict(fit.knn, newdata = Dtest)
class.lr = predict(fit.lr, newdata = Dtest)
#On crée une table de confusion pour chaque modèle
tab.knn = table(data = class.knn, reference = Dtest$type)
tab.lr = table(data = class.lr, reference = Dtest$type)
#On crée une matrice de confusion pour chaque modèle
mat.knn = confusionMatrix(tab.knn, positive = "spam")
mat.lr = confusionMatrix(tab.lr, positive = "spam")
#On affiche les taux de vrais positifs et de vrais négatifs pour chaque modèle
mat.knn$byClass[c("Specificity","Sensitivity")]
mat.lr$byClass[c("Specificity","Sensitivity")]
#On affiche la specificity
mat.knn$overall["Accuracy"]
mat.lr$overall["Accuracy"]
#AUC
calc_auc(g)$AUC
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
View(tabb)
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
#On utilise [f +- 1,96*sqrt(f*(1-f)/n)] pour calculer la marge d'erreur à chaque fois
tabb <- data.frame(model = c("knn","logit"),
AUC = c(0.944,0.944),
AUCmin = c(0.944-1.96*sqrt(0.944*(1-0.944)/4601),0.944-1.96*sqrt(0.944*(1-0.944)/4601)),
AUCmax = c(0.944+1.96*sqrt(0.944*(1-0.944)/4601),0.944+1.96*sqrt(0.944*(1-0.944)/4601)),
precision = c(0.945,0.945),
precisionmin = c(0.945-1.96*sqrt(0.945*(1-0.945)/4601),0.945-1.96*sqrt(0.945*(1-0.945)/4601)),
precisionmax = c(0.945+1.96*sqrt(0.945*(1-0.945)/4601),0.945+1.96*sqrt(0.945*(1-0.945)/4601)),
accuracy = c(0.925,0.925),
accuracymin = c(0.925-1.96*sqrt(0.925*(1-0.925)/4601),0.925-1.96*sqrt(0.925*(1-0.925)/4601)),
accuracymax = c(0.925+1.96*sqrt(0.925*(1-0.925)/4601),0.925+1.96*sqrt(0.925*(1-0.925)/4601)))
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
View(tabb)
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
"precision/spécifisity" = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
"precision/specifisity" = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#On refait le même tableau mais avec un interval [x,x] avec plus et moins 1,96*sqrt(f*(1-f)/n)
e <- 1.96*sqrt(tabb$precision*(1-tabb$precision)/4601)
tabb <- cbind(tabb, e)
colnames(tabb) <- c("model","AUC","precision","accuracy","e")
tabb
#On met tous les résultats dans un même tableau avec les colonnes suivantes : modèle, AUC, précision, accuracy
tabb <- data.frame(model = c("knn","logit"),
AUC = calc_auc(g)$AUC,
precision = c(mat.knn$byClass["Specificity"],mat.lr$byClass["Specificity"]),
accuracy = c(mat.knn$overall["Accuracy"],mat.lr$overall["Accuracy"]))
#AUC
calc_auc(g)$AUC
??nrow
??nrows
help(nrows)
help(nrow)
11 % 6
library(leaflet)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=174.768, lat=-36.852, popup="The birthplace of R")
m  # Print the map
devtools::install_github("tylermorganwall/rayshader")
install.packages("rayshader")
elmat %>%
sphere_shade(texture = "desert") %>%
add_water(detect_water(elmat), color = "lightblue") %>%
add_shadow(cloud_shade(elmat,zscale = 10, start_altitude = 500, end_altitude = 700,
sun_altitude = 45, attenuation_coef = 2, offset_y = 300,
cloud_cover = 0.55, frequency = 0.01, scale_y=3, fractal_levels = 32), 0) %>%
plot_3d(elmat, zscale = 10, fov = 0, theta = 135, zoom = 0.75, phi = 45, windowsize = c(1000, 800),
background="darkred")
library(rayshader)
elmat %>%
sphere_shade(texture = "desert") %>%
add_water(detect_water(elmat), color = "lightblue") %>%
add_shadow(cloud_shade(elmat,zscale = 10, start_altitude = 500, end_altitude = 700,
sun_altitude = 45, attenuation_coef = 2, offset_y = 300,
cloud_cover = 0.55, frequency = 0.01, scale_y=3, fractal_levels = 32), 0) %>%
plot_3d(elmat, zscale = 10, fov = 0, theta = 135, zoom = 0.75, phi = 45, windowsize = c(1000, 800),
background="darkred")
(table_contingence <- matrix(c(15, 25, 61, 84), nrow = 2, ncol = 2, byrow = TRUE))
(odds_ratio <- (table_contingence[1, 1] / table_contingence[1, 2]) / (table_contingence[2, 1] / table_contingence[2, 2]))
install.packages("furrr")
install.packages("future.apply")
rstudioapi::addTheme("https://raw.githubusercontent.com/dracula/rstudio/master/dracula.rstheme", apply = TRUE)
rstudioapi::addTheme("https://raw.githubusercontent.com/dracula/rstudio/master/dracula.rstheme", apply = TRUE)
remotes::install_github("anthonynorth/rscodeio")
rscodeio::install_theme()
rscodeio::install_theme()
remotes::install_github("anthonynorth/rscodeio")
rscodeio::install_theme()
activate_menu_theme()
library(rscodeio)
activate_menu_theme()
setwd("C:/Users/thoma/Desktop/Github/Web-page-Phishing-Detection")
